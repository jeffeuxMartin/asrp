{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# discrete unit model\n",
    "!wget https://dl.fbaipublicfiles.com/textless_nlp/gslm/hubert/km200/km.bin\n",
    "# tts model\n",
    "!wget https://dl.fbaipublicfiles.com/textless_nlp/gslm/hubert/tts_km200/tts_checkpoint_best.pt\n",
    "# waveglow\n",
    "!wget https://dl.fbaipublicfiles.com/textless_nlp/gslm/waveglow_256channels_new.pt\n",
    "# download dummpy speech\n",
    "!wget https://keithito.com/LJ-Speech-Dataset/LJ037-0171.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%pip install transformers asrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "import joblib\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy\n",
    "from transformers import (\n",
    "    Wav2Vec2FeatureExtractor, \n",
    "    HubertModel,\n",
    ")\n",
    "\n",
    "\n",
    "class HubertCode(object):\n",
    "    \"\"\"\n",
    "    HuBERT unit extraction tool.\n",
    "    Directly use it as a function to get units.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "        hubert_model, \n",
    "        km_path, \n",
    "        km_layer, \n",
    "        return_diff=False, \n",
    "        sampling_rate=16000,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize an object for HuBERT unit extraction.\n",
    "        \"\"\"\n",
    "        self.processor = (\n",
    "            Wav2Vec2FeatureExtractor\n",
    "                .from_pretrained(hubert_model))\n",
    "        self.model = (\n",
    "            HubertModel\n",
    "                .from_pretrained(hubert_model))\n",
    "        self.model.eval()\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.km_model = joblib.load(km_path)\n",
    "        self.km_layer = km_layer\n",
    "        self.return_diff = return_diff\n",
    "        self.C_np = (\n",
    "            self.km_model.cluster_centers_.transpose())\n",
    "        self.Cnorm_np = (self.C_np ** 2).sum(0, keepdims=True)\n",
    "\n",
    "        self.C = torch.from_numpy(self.C_np)\n",
    "        self.Cnorm = torch.from_numpy(self.Cnorm_np)\n",
    "        if torch.cuda.is_available():\n",
    "            self.C = self.C.cuda()\n",
    "            self.Cnorm = self.Cnorm.cuda()\n",
    "            self.model = self.model.cuda()\n",
    "\n",
    "    def __call__(self, filepath, merge=True):\n",
    "        \"\"\"\n",
    "        Unit extraction.\n",
    "        * merge: to collapse repeated units\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            speech, sr = torchaudio.load(filepath)\n",
    "            if sr != self.sampling_rate:\n",
    "                resampler = torchaudio.transforms.Resample(\n",
    "                    orig_freq=sr, \n",
    "                    new_freq=self.sampling_rate)\n",
    "                speech = resampler.forward(speech.squeeze(0)).numpy()\n",
    "            else:\n",
    "                speech = speech.squeeze(0).numpy()\n",
    "            input_values = self.processor(\n",
    "                speech, \n",
    "                return_tensors=\"pt\", \n",
    "                sampling_rate=self.sampling_rate\n",
    "            ).input_values\n",
    "            if torch.cuda.is_available():\n",
    "                input_values = input_values.cuda()\n",
    "            hidden_states = self.model(\n",
    "                input_values, \n",
    "                output_hidden_states=True\n",
    "            ).hidden_states\n",
    "            x = hidden_states[self.km_layer].squeeze()\n",
    "            dist = torch.sqrt(\n",
    "                x.pow(2).sum(1, keepdim=True)\n",
    "                - 2 * torch.matmul(x, self.C)\n",
    "                + self.Cnorm\n",
    "            )\n",
    "            # top K == 6\n",
    "            min_dist = torch.topk(dist.detach(), 6, dim=-1,largest=False)\n",
    "            pred_ind_array = min_dist.indices.cpu().numpy()\n",
    "            pred_values_array = min_dist.values.cpu().numpy()\n",
    "            greedy_output = min_dist.indices.T.cpu().numpy()[0]\n",
    "            print(\"greedy length\", len(greedy_output))\n",
    "            greedy_output = [k for k,_ in groupby(greedy_output)]\n",
    "            print(\"greedy merged length\", len(greedy_output))\n",
    "\n",
    "            sequences = [[[], 1.0]]\n",
    "            for i_row, v_row in zip(pred_ind_array, pred_values_array):\n",
    "                all_candidates = list()\n",
    "                exceed = False\n",
    "                for seq in sequences:\n",
    "                    tokens, score = seq\n",
    "                    for k, v in zip(i_row, v_row):\n",
    "                        norm_len_rate = (\n",
    "                            len([k for k, _ in groupby(tokens + [k])])\n",
    "                            / len(greedy_output))\n",
    "                        norm_dist_rate = (v/numpy.sum(v_row))\n",
    "                        candidate = [\n",
    "                            tokens + [k], \n",
    "                            score + norm_len_rate * norm_dist_rate]\n",
    "                        all_candidates.append(candidate)\n",
    "                ordered = sorted(all_candidates, \n",
    "                                 key=lambda tup: tup[1], \n",
    "                                 reverse=False)\n",
    "                sequences = ordered[:200]\n",
    "            \n",
    "            # top beamsearch result\n",
    "            unitcode = [k for k,_ in groupby(sequences[0][0])]\n",
    "            if self.return_diff:\n",
    "                return (\n",
    "                    unitcode, \n",
    "                    x.cpu() - torch.index_select(\n",
    "                        torch.tensor(self.C_np.transpose())\n",
    "                            .cpu(), \n",
    "                        0, \n",
    "                        min_dist.indices.cpu()))\n",
    "            else:\n",
    "                return unitcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hc = HubertCode(\n",
    "    \"facebook/hubert-base-ls960\", \n",
    "    './km.bin', \n",
    "    km_layer=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "code = hc('LJ037-0171.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import asrp\n",
    "cs = asrp.Code2Speech(\n",
    "    tts_checkpoint='./tts_checkpoint_best.pt', \n",
    "    waveglow_checkpint='waveglow_256channels_new.pt', \n",
    "    end_tok=201, \n",
    "    code_begin_pad=1)\n",
    "\n",
    "# play on notebook\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(data=cs(code), autoplay=False, rate=cs.sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
